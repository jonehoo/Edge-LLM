"""
Streamlit Webåº”ç”¨
æ¸©åº¦æ•°æ®åˆ†æå¯è§†åŒ–ç•Œé¢
"""

import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.analyzer import TemperatureAnalyzer

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="è¾¹ç¼˜ç‰©è”ç½‘æ¸©åº¦åˆ†æç³»ç»Ÿ",
    page_icon="ğŸŒ¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .stAlert {
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–åˆ†æå™¨ï¼ˆä½¿ç”¨ç¼“å­˜ï¼Œä½†å…è®¸åˆ·æ–°ï¼‰
@st.cache_resource
def init_analyzer():
    """åˆå§‹åŒ–åˆ†æå™¨ï¼ˆç¼“å­˜ï¼‰"""
    import yaml
    from pathlib import Path
    
    # è¯»å–é…ç½®æ–‡ä»¶
    config_path = Path(__file__).parent.parent / "config" / "config.yaml"
    use_database = False
    model_type = "local"
    model_path = "models/qwen-0.6b.gguf"
    n_ctx = 2048
    n_threads = 4
    openai_api_key = None
    openai_model = "gpt-3.5-turbo"
    openai_base_url = None
    
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            
            # æ•°æ®æºé…ç½®
            data_config = config.get('data', {})
            use_database = data_config.get('source', 'json') == 'database'
            
            # æ¨¡å‹é…ç½®
            model_config = config.get('model', {})
            model_type = model_config.get('type', 'local')
            model_path = model_config.get('path', 'models/qwen-0.6b.gguf')
            n_ctx = model_config.get('n_ctx', 2048)
            n_threads = model_config.get('n_threads', 4)
            
            # OpenAIé…ç½®
            openai_config = config.get('openai', {})
            openai_api_key = openai_config.get('api_key')
            openai_model = openai_config.get('model', 'gpt-3.5-turbo')
            openai_base_url = openai_config.get('base_url')
    
    return TemperatureAnalyzer(
        use_database=use_database,
        model_type=model_type,
        model_path=model_path,
        n_ctx=n_ctx,
        n_threads=n_threads,
        openai_api_key=openai_api_key,
        openai_model=openai_model,
        openai_base_url=openai_base_url
    )


# ä¸»åº”ç”¨
def main():
    # æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸŒ¡ï¸ è¾¹ç¼˜ç‰©è”ç½‘æ¸©åº¦åˆ†æç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = init_analyzer()
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“Š å¯¼èˆª")
        
        page = st.radio(
            "é€‰æ‹©é¡µé¢",
            ["è®¾å¤‡æ¦‚è§ˆ", "è®¾å¤‡è¯¦æƒ…", "ç»¼åˆåˆ†æ", "æ•°æ®å¯è§†åŒ–"],
            label_visibility="collapsed"
        )
        
        st.divider()
        
        # æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", width='stretch', key="manual_refresh_btn"):
            # æ¸…é™¤ç¼“å­˜ä»¥å¼ºåˆ¶åˆ·æ–°
            if hasattr(analyzer.data_loader, 'clear_cache'):
                analyzer.data_loader.clear_cache()
            st.rerun()
        
        st.divider()
        
        # æ¨¡å‹çŠ¶æ€
        st.subheader("ğŸ¤– æ¨¡å‹çŠ¶æ€")
        model_info = analyzer.llm_service.get_model_info()
        if analyzer.llm_service.is_available():
            if model_info['type'] == 'OpenAI':
                st.success(f"âœ… OpenAIæ¨¡å‹å·²è¿æ¥ ({model_info['model']})")
            else:
                st.success(f"âœ… æœ¬åœ°å¤§æ¨¡å‹å·²åŠ è½½")
                st.caption(f"æ¨¡å‹: {Path(model_info['model']).name}")
        else:
            if model_info['type'] == 'OpenAI':
                st.warning("âš ï¸ OpenAIè¿æ¥å¤±è´¥")
                st.info("æç¤ºï¼šè¯·æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥")
            else:
                st.warning("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆæ¨¡å‹æœªåŠ è½½ï¼‰")
                st.info("æç¤ºï¼šå®‰è£…llama-cpp-pythonå¹¶ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
        
        st.divider()
        
        # æ•°æ®ä¿¡æ¯
        st.subheader("ğŸ“ æ•°æ®ä¿¡æ¯")
        devices = analyzer.get_device_list()
        st.metric("è®¾å¤‡æ•°é‡", len(devices))
        total_readings = sum(d['readings_count'] for d in devices)
        st.metric("æ€»è¯»æ•°", total_readings)
        
        # æ˜¾ç¤ºæœ€åæ›´æ–°æ—¶é—´
        from datetime import datetime
        st.caption(f"æœ€åæ›´æ–°: {datetime.now().strftime('%H:%M:%S')}")
    
    # æ ¹æ®é€‰æ‹©çš„é¡µé¢æ˜¾ç¤ºå†…å®¹
    if page == "è®¾å¤‡æ¦‚è§ˆ":
        show_device_overview(analyzer)
    elif page == "è®¾å¤‡è¯¦æƒ…":
        show_device_detail(analyzer)
    elif page == "ç»¼åˆåˆ†æ":
        show_comprehensive_analysis(analyzer)
    elif page == "æ•°æ®å¯è§†åŒ–":
        show_data_visualization(analyzer)

def show_device_overview(analyzer):
    """æ˜¾ç¤ºè®¾å¤‡æ¦‚è§ˆ"""
    st.header("ğŸ“‹ è®¾å¤‡æ¦‚è§ˆ")
    
    devices = analyzer.get_device_list()
    
    if not devices:
        st.warning("æ²¡æœ‰æ‰¾åˆ°è®¾å¤‡æ•°æ®")
        return
    
    # è®¾å¤‡å¡ç‰‡
    cols = st.columns(len(devices))
    for idx, device in enumerate(devices):
        with cols[idx]:
            st.metric(
                label=device['device_name'],
                value=device['readings_count'],
                delta=f"{device['location']}"
            )
    
    st.divider()
    
    # è®¾å¤‡åˆ—è¡¨è¡¨æ ¼
    st.subheader("è®¾å¤‡åˆ—è¡¨")
    device_data = {
        'è®¾å¤‡ID': [d['device_id'] for d in devices],
        'è®¾å¤‡åç§°': [d['device_name'] for d in devices],
        'ä½ç½®': [d['location'] for d in devices],
        'è¯»æ•°æ•°é‡': [d['readings_count'] for d in devices]
    }
    st.dataframe(device_data, width='stretch', hide_index=True)
    
    # å¿«é€Ÿç»Ÿè®¡
    st.subheader("ğŸ“Š å¿«é€Ÿç»Ÿè®¡")
    all_stats = analyzer.data_loader.get_statistics()
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("å¹³å‡æ¸©åº¦", f"{all_stats.get('avg_temperature', 0):.2f}Â°C")
    with col2:
        st.metric("æœ€ä½æ¸©åº¦", f"{all_stats.get('min_temperature', 0):.2f}Â°C")
    with col3:
        st.metric("æœ€é«˜æ¸©åº¦", f"{all_stats.get('max_temperature', 0):.2f}Â°C")
    with col4:
        st.metric("æ¸©åº¦èŒƒå›´", f"{all_stats.get('temperature_range', 0):.2f}Â°C")

def show_device_detail(analyzer):
    """æ˜¾ç¤ºè®¾å¤‡è¯¦æƒ…"""
    st.header("ğŸ” è®¾å¤‡è¯¦æƒ…åˆ†æ")
    
    devices = analyzer.get_device_list()
    if not devices:
        st.warning("æ²¡æœ‰æ‰¾åˆ°è®¾å¤‡æ•°æ®")
        return
    
    # è®¾å¤‡é€‰æ‹©
    device_options = {f"{d['device_name']} ({d['device_id']})": d['device_id'] 
                     for d in devices}
    selected_device_name = st.selectbox("é€‰æ‹©è®¾å¤‡", list(device_options.keys()))
    device_id = device_options[selected_device_name]
    
    st.divider()
    
    # åŠ è½½åˆ†æç»“æœ
    with st.spinner("æ­£åœ¨åˆ†æè®¾å¤‡æ•°æ®..."):
        analysis = analyzer.analyze_device(device_id)
    
    # ç»Ÿè®¡ä¿¡æ¯
    st.subheader("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
    stats = analysis['statistics']
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("å¹³å‡æ¸©åº¦", f"{stats.get('avg_temperature', 0):.2f}Â°C")
    with col2:
        st.metric("æœ€ä½æ¸©åº¦", f"{stats.get('min_temperature', 0):.2f}Â°C")
    with col3:
        st.metric("æœ€é«˜æ¸©åº¦", f"{stats.get('max_temperature', 0):.2f}Â°C")
    with col4:
        st.metric("æ€»è¯»æ•°", stats.get('total_readings', 0))
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ­£å¸¸", stats.get('normal_count', 0), delta="æ­£å¸¸çŠ¶æ€")
    with col2:
        st.metric("è­¦å‘Š", stats.get('warning_count', 0), delta="è­¦å‘ŠçŠ¶æ€", delta_color="inverse")
    with col3:
        st.metric("å‘Šè­¦", stats.get('alert_count', 0), delta="å‘Šè­¦çŠ¶æ€", delta_color="inverse")
    
    # æœ€æ–°è¯»æ•°
    st.subheader("ğŸ“¡ æœ€æ–°è¯»æ•°")
    latest = analysis['latest_reading']
    if latest:
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ—¶é—´", latest['timestamp'])
        with col2:
            st.metric("æ¸©åº¦", f"{latest['temperature']}Â°C")
        with col3:
            st.metric("æ¹¿åº¦", f"{latest['humidity']}%")
        with col4:
            status_emoji = {"normal": "âœ…", "warning": "âš ï¸", "alert": "ğŸš¨"}.get(latest['status'], "â“")
            st.metric("çŠ¶æ€", f"{status_emoji} {latest['status']}")
    
    # è¶‹åŠ¿åˆ†æ
    st.subheader("ğŸ“Š è¶‹åŠ¿åˆ†æ")
    trend = analysis['trend']
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å½“å‰æ¸©åº¦", f"{trend.get('current_temp', 0):.2f}Â°C")
    with col2:
        trend_emoji = "ğŸ“ˆ" if trend.get('trend') == "ä¸Šå‡" else "ğŸ“‰" if trend.get('trend') == "ä¸‹é™" else "â¡ï¸"
        st.metric("è¶‹åŠ¿", f"{trend_emoji} {trend.get('trend', 'N/A')}")
    with col3:
        st.metric("æ³¢åŠ¨æ€§", f"{trend.get('volatility', 0):.2f}")
    
    # å¼‚å¸¸æ£€æµ‹
    if analysis['anomalies_count'] > 0:
        st.subheader("âš ï¸ å¼‚å¸¸æ£€æµ‹")
        st.warning(f"æ£€æµ‹åˆ° {analysis['anomalies_count']} ä¸ªå¼‚å¸¸è¯»æ•°")
        anomalies_df = {
            'æ—¶é—´': [a['timestamp'] for a in analysis['anomalies']],
            'æ¸©åº¦': [a['temperature'] for a in analysis['anomalies']],
            'Z-score': [a['z_score'] for a in analysis['anomalies']],
            'ç±»å‹': [a['anomaly_type'] for a in analysis['anomalies']]
        }
        st.dataframe(anomalies_df, width='stretch', hide_index=True)
    else:
        st.success("âœ… æœªæ£€æµ‹åˆ°å¼‚å¸¸")
    
    # LLMåˆ†æï¼ˆæµå¼è¾“å‡ºï¼‰
    st.subheader("ğŸ¤– AIæ™ºèƒ½åˆ†æ")
    
    # æ·»åŠ æµå¼è¾“å‡ºé€‰é¡¹
    use_stream = st.checkbox("å¯ç”¨æµå¼è¾“å‡º", value=True, help="å®æ—¶æ˜¾ç¤ºAIåˆ†æç”Ÿæˆè¿‡ç¨‹")
    
    if use_stream:
        # æµå¼è¾“å‡º
        analysis_placeholder = st.empty()
        full_text = ""
        
        with st.spinner("æ­£åœ¨ç”ŸæˆAIåˆ†æ..."):
            for chunk in analyzer.analyze_device_stream(device_id, "comprehensive"):
                full_text += chunk
                analysis_placeholder.markdown(full_text)
        
        # å®Œæˆåè¿›è¡Œåå¤„ç†
        from src.llm_service import LLMService
        temp_llm = LLMService()
        cleaned_text = temp_llm._remove_repetition(full_text)
        cleaned_text = temp_llm._clean_prompt_artifacts(cleaned_text)
        analysis_placeholder.markdown(cleaned_text)
    else:
        # ä¼ ç»Ÿæ–¹å¼ï¼ˆä¸€æ¬¡æ€§è¾“å‡ºï¼‰
        with st.spinner("æ­£åœ¨åˆ†æè®¾å¤‡æ•°æ®..."):
            analysis = analyzer.analyze_device(device_id)
        st.markdown(analysis['llm_analysis'])

def show_comprehensive_analysis(analyzer):
    """æ˜¾ç¤ºç»¼åˆåˆ†æ"""
    st.header("ğŸ”¬ ç»¼åˆåˆ†æ")
    
    # åˆ†æç±»å‹é€‰æ‹©
    analysis_type = st.radio(
        "é€‰æ‹©åˆ†æç±»å‹",
        ["ç»¼åˆåˆ†æ", "å¼‚å¸¸åˆ†æ", "è¶‹åŠ¿åˆ†æ", "å»ºè®®æ–¹æ¡ˆ"],
        horizontal=True
    )
    
    analysis_type_map = {
        "ç»¼åˆåˆ†æ": "comprehensive",
        "å¼‚å¸¸åˆ†æ": "anomaly",
        "è¶‹åŠ¿åˆ†æ": "trend",
        "å»ºè®®æ–¹æ¡ˆ": "recommendation"
    }
    
    # è®¾å¤‡é€‰æ‹©ï¼ˆå¯é€‰ï¼‰
    devices = analyzer.get_device_list()
    device_options = {f"{d['device_name']} ({d['device_id']})": d['device_id'] 
                     for d in devices}
    device_options["æ‰€æœ‰è®¾å¤‡"] = None
    
    selected_device_name = st.selectbox("é€‰æ‹©è®¾å¤‡ï¼ˆå¯é€‰ï¼‰", list(device_options.keys()))
    device_id = device_options[selected_device_name]
    
    # æµå¼è¾“å‡ºé€‰é¡¹
    use_stream = st.checkbox("å¯ç”¨æµå¼è¾“å‡º", value=True, help="å®æ—¶æ˜¾ç¤ºAIåˆ†æç”Ÿæˆè¿‡ç¨‹")
    
    # æ‰§è¡Œåˆ†æ
    if st.button("å¼€å§‹åˆ†æ", type="primary"):
        if device_id:
            if use_stream:
                # æµå¼è¾“å‡º
                analysis_placeholder = st.empty()
                full_text = ""
                
                with st.spinner("æ­£åœ¨ç”ŸæˆAIåˆ†ææŠ¥å‘Š..."):
                    for chunk in analyzer.analyze_device_stream(device_id, analysis_type_map[analysis_type]):
                        full_text += chunk
                        analysis_placeholder.markdown(full_text)
                
                # åå¤„ç†
                from src.llm_service import LLMService
                temp_llm = LLMService()
                cleaned_text = temp_llm._remove_repetition(full_text)
                cleaned_text = temp_llm._clean_prompt_artifacts(cleaned_text)
                analysis_placeholder.markdown(cleaned_text)
            else:
                # ä¼ ç»Ÿæ–¹å¼
                with st.spinner("æ­£åœ¨ç”ŸæˆAIåˆ†ææŠ¥å‘Š..."):
                    analysis = analyzer.analyze_device(device_id, analysis_type_map[analysis_type])
                    st.markdown(analysis['llm_analysis'])
        else:
            # æ‰€æœ‰è®¾å¤‡çš„åˆ†æï¼ˆæš‚æ—¶ä¸æ”¯æŒæµå¼ï¼‰
            with st.spinner("æ­£åœ¨ç”ŸæˆAIåˆ†ææŠ¥å‘Š..."):
                all_analysis = analyzer.get_all_devices_analysis()
                st.markdown(all_analysis['llm_analysis'])

def show_data_visualization(analyzer):
    """æ˜¾ç¤ºæ•°æ®å¯è§†åŒ–"""
    st.header("ğŸ“Š æ•°æ®å¯è§†åŒ–")
    
    devices = analyzer.get_device_list()
    if not devices:
        st.warning("æ²¡æœ‰æ‰¾åˆ°è®¾å¤‡æ•°æ®")
        return
    
    # è®¾å¤‡é€‰æ‹©
    device_options = {f"{d['device_name']} ({d['device_id']})": d['device_id'] 
                     for d in devices}
    selected_device_name = st.selectbox("é€‰æ‹©è®¾å¤‡", list(device_options.keys()))
    device_id = device_options[selected_device_name]
    
    # è·å–å›¾è¡¨æ•°æ®
    chart_data = analyzer.get_temperature_chart_data(device_id)
    
    if not chart_data['timestamps']:
        st.warning("è¯¥è®¾å¤‡æ²¡æœ‰æ•°æ®")
        return
    
    # æ¸©åº¦è¶‹åŠ¿å›¾
    st.subheader("ğŸŒ¡ï¸ æ¸©åº¦è¶‹åŠ¿")
    fig_temp = go.Figure()
    fig_temp.add_trace(go.Scatter(
        x=chart_data['timestamps'],
        y=chart_data['temperatures'],
        mode='lines+markers',
        name='æ¸©åº¦',
        line=dict(color='#1f77b4', width=2),
        marker=dict(size=6)
    ))
    fig_temp.update_layout(
        xaxis_title="æ—¶é—´",
        yaxis_title="æ¸©åº¦ (Â°C)",
        hovermode='x unified',
        height=400
    )
    st.plotly_chart(fig_temp, width='stretch')
    
    # æ¸©åº¦å’Œæ¹¿åº¦åŒè½´å›¾
    if chart_data['humidity']:
        st.subheader("ğŸŒ¡ï¸ğŸ’§ æ¸©åº¦ä¸æ¹¿åº¦")
        fig_dual = make_subplots(specs=[[{"secondary_y": True}]])
        fig_dual.add_trace(
            go.Scatter(x=chart_data['timestamps'], y=chart_data['temperatures'],
                      name="æ¸©åº¦", line=dict(color='#ff7f0e')),
            secondary_y=False
        )
        fig_dual.add_trace(
            go.Scatter(x=chart_data['timestamps'], y=chart_data['humidity'],
                      name="æ¹¿åº¦", line=dict(color='#2ca02c')),
            secondary_y=True
        )
        fig_dual.update_xaxes(title_text="æ—¶é—´")
        fig_dual.update_yaxes(title_text="æ¸©åº¦ (Â°C)", secondary_y=False)
        fig_dual.update_yaxes(title_text="æ¹¿åº¦ (%)", secondary_y=True)
        fig_dual.update_layout(height=400, hovermode='x unified')
        st.plotly_chart(fig_dual, width='stretch')
    
    # æ•°æ®è¡¨æ ¼
    st.subheader("ğŸ“‹ åŸå§‹æ•°æ®")
    df = analyzer.get_dataframe(device_id)
    st.dataframe(df, width='stretch')

if __name__ == "__main__":
    main()

